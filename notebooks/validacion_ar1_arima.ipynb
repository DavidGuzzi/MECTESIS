{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validaci√≥n AR(1) - ARIMA: An√°lisis de Sesgo en Pron√≥sticos\n",
    "\n",
    "## Objetivo\n",
    "\n",
    "Este notebook implementa paso a paso una simulaci√≥n Monte Carlo para investigar el comportamiento del **sesgo** en pron√≥sticos generados por ARIMA(1,0,0) sobre series simuladas de un proceso AR(1).\n",
    "\n",
    "**Contexto**: En experimentos previos se observ√≥ que ARIMA(1,0,0) presenta sesgo significativamente distinto de cero al pronosticar series AR(1), cuando te√≥ricamente deber√≠a ser aproximadamente cero.\n",
    "\n",
    "## Proceso AR(1)\n",
    "\n",
    "El Data Generating Process (DGP) es:\n",
    "\n",
    "$$\n",
    "y_t = \\mu + \\phi(y_{t-1} - \\mu) + \\varepsilon_t, \\quad \\varepsilon_t \\sim \\mathcal{N}(0, \\sigma^2)\n",
    "$$\n",
    "\n",
    "**Propiedades te√≥ricas (para |œÜ| < 1)**:\n",
    "- Media: $E[y_t] = \\mu$\n",
    "- Varianza: $\\text{Var}(y_t) = \\frac{\\sigma^2}{1 - \\phi^2}$\n",
    "- Autocorrelaci√≥n: $\\rho(k) = \\phi^k$\n",
    "\n",
    "## ¬øPor qu√© ARIMA(1,0,0) deber√≠a ser insesgado?\n",
    "\n",
    "Si el verdadero DGP es AR(1) y ajustamos ARIMA(1,0,0) (que es equivalente a AR(1)), el modelo est√° **correctamente especificado**. En este caso:\n",
    "\n",
    "1. Los par√°metros estimados $\\hat{\\phi}$ y $\\hat{\\mu}$ convergen a los verdaderos valores œÜ y Œº (asint√≥ticamente).\n",
    "2. Los pron√≥sticos son proyecciones √≥ptimas (minimzan MSE).\n",
    "3. El sesgo $\\text{Bias}(h) = E[y_{T+h} - \\hat{y}_{T+h}] \\approx 0$.\n",
    "\n",
    "**Sin embargo**, en muestras finitas:\n",
    "- Puede existir **sesgo finite-sample** en la estimaci√≥n de par√°metros.\n",
    "- El sesgo puede crecer con el horizonte de pron√≥stico.\n",
    "- La longitud de la serie $T$ afecta la magnitud del sesgo.\n",
    "\n",
    "Este notebook investiga estas hip√≥tesis emp√≠ricamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 1. Introducci√≥n y Setup\n",
    "\n",
    "Cargamos las librer√≠as necesarias y configuramos la reproducibilidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "# Configuraci√≥n de visualizaci√≥n\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "warnings.filterwarnings('ignore')  # Suprimir warnings de convergencia de ARIMA\n",
    "\n",
    "# Reproducibilidad\n",
    "SEED = 12345\n",
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "print(f\"‚úì Librer√≠as cargadas\")\n",
    "print(f\"‚úì Seed configurado: {SEED}\")\n",
    "print(f\"‚úì Notebook listo para ejecutar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 2. Paso a Paso - UNA Simulaci√≥n\n",
    "\n",
    "Antes de ejecutar 500 simulaciones Monte Carlo, mostramos el flujo completo con **una sola serie**.\n",
    "\n",
    "Esto permite:\n",
    "1. Verificar que la simulaci√≥n AR(1) funciona correctamente.\n",
    "2. Inspeccionar visualmente la serie y sus propiedades.\n",
    "3. Ver c√≥mo ARIMA ajusta y pronostica.\n",
    "4. Entender que en una sola simulaci√≥n el error puede ser != 0 (variabilidad muestral)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Funci√≥n de Simulaci√≥n AR(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_ar1(T, phi, mu=0.0, sigma=1.0, burn_in=200, rng=None):\n",
    "    \"\"\"\n",
    "    Simula un proceso AR(1): y_t = mu + phi * (y_{t-1} - mu) + eps_t\n",
    "    \n",
    "    Par√°metros:\n",
    "    -----------\n",
    "    T : int\n",
    "        Longitud de la serie retornada (despu√©s del burn-in)\n",
    "    phi : float\n",
    "        Coeficiente autoregresivo (|phi| < 1 para estacionariedad)\n",
    "    mu : float\n",
    "        Media del proceso\n",
    "    sigma : float\n",
    "        Desviaci√≥n est√°ndar de las innovaciones\n",
    "    burn_in : int\n",
    "        N√∫mero de observaciones iniciales a descartar\n",
    "    rng : np.random.Generator\n",
    "        Generador de n√∫meros aleatorios\n",
    "    \n",
    "    Retorna:\n",
    "    --------\n",
    "    np.ndarray : Serie de tiempo de longitud T\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "    \n",
    "    # Generar T + burn_in observaciones\n",
    "    total_T = T + burn_in\n",
    "    y = np.zeros(total_T)\n",
    "    y[0] = mu  # Inicializar en la media\n",
    "    \n",
    "    # Evoluci√≥n del proceso\n",
    "    for t in range(1, total_T):\n",
    "        eps = rng.normal(0, sigma)\n",
    "        y[t] = mu + phi * (y[t-1] - mu) + eps\n",
    "    \n",
    "    # Descartar burn-in\n",
    "    return y[burn_in:]\n",
    "\n",
    "print(\"‚úì Funci√≥n simulate_ar1() definida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Generar UNA Serie AR(1)\n",
    "\n",
    "Usamos los mismos par√°metros del experimento principal:\n",
    "- T = 200 observaciones\n",
    "- œÜ = 0.7 (persistencia moderada)\n",
    "- Œº = 0.0\n",
    "- œÉ = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Par√°metros del experimento\n",
    "T = 200\n",
    "phi = 0.7\n",
    "mu = 0.0\n",
    "sigma = 1.0\n",
    "\n",
    "# Simular UNA serie\n",
    "y = simulate_ar1(T, phi, mu, sigma, burn_in=200, rng=rng)\n",
    "\n",
    "# Propiedades te√≥ricas\n",
    "var_teorica = sigma**2 / (1 - phi**2)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"SERIE AR(1) SIMULADA\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Longitud: {len(y)} observaciones\")\n",
    "print(f\"\\nPropiedades muestrales:\")\n",
    "print(f\"  Media muestral:    {y.mean():8.4f}  (te√≥rica: {mu:.4f})\")\n",
    "print(f\"  Varianza muestral: {y.var():8.4f}  (te√≥rica: {var_teorica:.4f})\")\n",
    "print(f\"  Desv. est√°ndar:    {y.std():8.4f}\")\n",
    "print(f\"  M√≠nimo:            {y.min():8.4f}\")\n",
    "print(f\"  M√°ximo:            {y.max():8.4f}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizaci√≥n de la Serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
    "\n",
    "# Serie temporal\n",
    "axes[0].plot(y, linewidth=1, color='steelblue')\n",
    "axes[0].axhline(mu, color='red', linestyle='--', linewidth=1.5, label=f'Œº={mu}')\n",
    "axes[0].set_xlabel('Tiempo (t)')\n",
    "axes[0].set_ylabel('y_t')\n",
    "axes[0].set_title('Serie Temporal AR(1) Simulada')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# ACF\n",
    "plot_acf(y, lags=20, ax=axes[1], color='steelblue')\n",
    "axes[1].set_title('Funci√≥n de Autocorrelaci√≥n (ACF)')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# PACF\n",
    "plot_pacf(y, lags=20, ax=axes[2], color='steelblue', method='ywm')\n",
    "axes[2].set_title('Funci√≥n de Autocorrelaci√≥n Parcial (PACF)')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Interpretaci√≥n:\")\n",
    "print(\"  - ACF: Decaimiento exponencial (caracter√≠stico de AR(1))\")\n",
    "print(\"  - PACF: Solo el primer lag es significativo (confirma AR(1))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Split Train/Test\n",
    "\n",
    "Separamos la serie en:\n",
    "- **Training**: Primeras $T - h = 188$ observaciones (para ajustar el modelo)\n",
    "- **Test**: √öltimas $h = 12$ observaciones (para evaluar pron√≥sticos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 12\n",
    "T_train = T - horizon\n",
    "\n",
    "y_train = y[:T_train]  # Primeras 188 observaciones\n",
    "y_test = y[T_train:]    # √öltimas 12 observaciones\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"DIVISI√ìN TRAIN/TEST\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Training size: {len(y_train)} observaciones (t=1 a t={T_train})\")\n",
    "print(f\"Test size:     {len(y_test)} observaciones (t={T_train+1} a t={T})\")\n",
    "print(f\"\\nValores de test (horizonte h=1 a h={horizon}):\")\n",
    "for h, val in enumerate(y_test, start=1):\n",
    "    print(f\"  h={h:2d}: y_test = {val:8.4f}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Ajustar ARIMA(1,0,0)\n",
    "\n",
    "Ajustamos el modelo ARIMA(1,0,0) a los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustar modelo\n",
    "model = ARIMA(y_train, order=(1, 0, 0))\n",
    "fitted_model = model.fit()\n",
    "\n",
    "# Extraer par√°metros estimados\n",
    "phi_hat = fitted_model.params['ar.L1']\n",
    "mu_hat = fitted_model.params['const']\n",
    "sigma_hat = np.sqrt(fitted_model.params['sigma2'])\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"MODELO ARIMA(1,0,0) AJUSTADO\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nPar√°metros estimados:\")\n",
    "print(f\"  œÜÃÇ (AR coef):     {phi_hat:8.5f}  (verdadero: {phi:.5f})\")\n",
    "print(f\"  ŒºÃÇ (constante):   {mu_hat:8.5f}  (verdadero: {mu:.5f})\")\n",
    "print(f\"  œÉÃÇ (residuos):    {sigma_hat:8.5f}  (verdadero: {sigma:.5f})\")\n",
    "print(f\"\\nError de estimaci√≥n:\")\n",
    "print(f\"  Error en œÜ: {phi_hat - phi:+.5f} ({100*(phi_hat - phi)/phi:+.2f}%)\")\n",
    "print(f\"  Error en Œº: {mu_hat - mu:+.5f}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Mostrar resumen completo\n",
    "print(\"\\nResumen estad√≠stico completo:\")\n",
    "print(fitted_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagn√≥stico de Residuos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuos = fitted_model.resid\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 8))\n",
    "\n",
    "# Serie de residuos\n",
    "axes[0, 0].plot(residuos, linewidth=1, color='coral')\n",
    "axes[0, 0].axhline(0, color='black', linestyle='--', linewidth=1)\n",
    "axes[0, 0].set_xlabel('Tiempo')\n",
    "axes[0, 0].set_ylabel('Residuos')\n",
    "axes[0, 0].set_title('Serie de Residuos')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Histograma\n",
    "axes[0, 1].hist(residuos, bins=30, edgecolor='black', alpha=0.7, color='coral')\n",
    "axes[0, 1].axvline(0, color='red', linestyle='--', linewidth=2)\n",
    "axes[0, 1].set_xlabel('Residuos')\n",
    "axes[0, 1].set_ylabel('Frecuencia')\n",
    "axes[0, 1].set_title(f'Distribuci√≥n de Residuos (media={residuos.mean():.4f})')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Q-Q plot\n",
    "stats.probplot(residuos, dist=\"norm\", plot=axes[1, 0])\n",
    "axes[1, 0].set_title('Q-Q Plot (Normalidad)')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# ACF de residuos\n",
    "plot_acf(residuos, lags=20, ax=axes[1, 1], color='coral')\n",
    "axes[1, 1].set_title('ACF de Residuos')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Diagn√≥stico:\")\n",
    "print(f\"  - Media de residuos: {residuos.mean():.6f} (deber√≠a ‚âà 0)\")\n",
    "print(f\"  - Desv. est. residuos: {residuos.std():.4f}\")\n",
    "print(\"  - Los residuos deber√≠an parecer ruido blanco gaussiano\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. Generar Pron√≥sticos\n",
    "\n",
    "Generamos pron√≥sticos para los pr√≥ximos $h=12$ pasos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar pron√≥sticos\n",
    "forecast_result = fitted_model.get_forecast(steps=horizon)\n",
    "y_hat = forecast_result.predicted_mean.values  # Array de 12 pron√≥sticos\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"PRON√ìSTICOS vs VALORES REALES\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'h':>3s}  {'y_test':>10s}  {'y_hat':>10s}  {'Error':>10s}\")\n",
    "print(\"-\"*70)\n",
    "for h in range(horizon):\n",
    "    error = y_test[h] - y_hat[h]\n",
    "    print(f\"{h+1:3d}  {y_test[h]:10.4f}  {y_hat[h]:10.4f}  {error:+10.4f}\")\n",
    "\n",
    "# Calcular errores\n",
    "errors = y_test - y_hat\n",
    "print(\"-\"*70)\n",
    "print(f\"Error promedio (esta simulaci√≥n): {errors.mean():+.6f}\")\n",
    "print(f\"RMSE (esta simulaci√≥n):            {np.sqrt((errors**2).mean()):.4f}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizaci√≥n de Pron√≥sticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Gr√°fico 1: Serie completa con pron√≥sticos\n",
    "axes[0].plot(range(len(y_train)), y_train, label='Training', color='steelblue', linewidth=1.5)\n",
    "axes[0].plot(range(len(y_train), len(y)), y_test, label='Test (real)', color='green', linewidth=2, marker='o')\n",
    "axes[0].plot(range(len(y_train), len(y)), y_hat, label='Pron√≥stico', color='red', linewidth=2, linestyle='--', marker='x')\n",
    "axes[0].axvline(len(y_train), color='black', linestyle=':', linewidth=1.5, label='Split train/test')\n",
    "axes[0].set_xlabel('Tiempo (t)')\n",
    "axes[0].set_ylabel('y_t')\n",
    "axes[0].set_title('Serie Completa: Train, Test y Pron√≥sticos')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Gr√°fico 2: Errores por horizonte\n",
    "axes[1].bar(range(1, horizon + 1), errors, color='coral', edgecolor='black', alpha=0.7)\n",
    "axes[1].axhline(0, color='black', linestyle='--', linewidth=1.5)\n",
    "axes[1].axhline(errors.mean(), color='red', linestyle='-', linewidth=2, label=f'Media={errors.mean():.4f}')\n",
    "axes[1].set_xlabel('Horizonte (h)')\n",
    "axes[1].set_ylabel('Error (y_test - y_hat)')\n",
    "axes[1].set_title('Errores de Pron√≥stico por Horizonte')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Interpretaci√≥n:\")\n",
    "print(\"  - En UNA simulaci√≥n, el error promedio puede ser != 0\")\n",
    "print(\"  - Esto es variabilidad muestral, NO sesgo sistem√°tico\")\n",
    "print(\"  - Solo despu√©s de Monte Carlo (promediando muchas simulaciones) esperamos bias ‚âà 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 3. Monte Carlo - 500 Simulaciones\n",
    "\n",
    "Ahora escalamos a **500 simulaciones** para calcular la descomposici√≥n sesgo-varianza.\n",
    "\n",
    "## Proceso:\n",
    "1. Para cada simulaci√≥n $s = 1, \\ldots, 500$:\n",
    "   - Simular serie AR(1) de longitud $T=200$\n",
    "   - Separar en train (188 obs) / test (12 obs)\n",
    "   - Ajustar ARIMA(1,0,0) en train\n",
    "   - Pronosticar $h=12$ pasos\n",
    "   - Calcular errores: $e_{s,h} = y_{\\text{test},h} - \\hat{y}_h$\n",
    "\n",
    "2. Agregar errores en matriz de dimensi√≥n $(500, 12)$\n",
    "\n",
    "3. Calcular m√©tricas por horizonte:\n",
    "   - **Sesgo**: $\\text{Bias}(h) = \\frac{1}{500}\\sum_{s=1}^{500} e_{s,h}$\n",
    "   - **Varianza**: $\\text{Var}(h) = \\frac{1}{499}\\sum_{s=1}^{500} (e_{s,h} - \\overline{e}_h)^2$\n",
    "   - **MSE**: $\\text{MSE}(h) = \\frac{1}{500}\\sum_{s=1}^{500} e_{s,h}^2$\n",
    "   - **RMSE**: $\\text{RMSE}(h) = \\sqrt{\\text{MSE}(h)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Funci√≥n para UNA Simulaci√≥n Completa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_one_simulation(T, horizon, phi, mu, sigma, burn_in, rng):\n",
    "    \"\"\"\n",
    "    Ejecuta una simulaci√≥n completa: simular ‚Üí split ‚Üí ajustar ‚Üí pronosticar ‚Üí errores\n",
    "    \n",
    "    Retorna:\n",
    "    --------\n",
    "    np.ndarray : Vector de errores de longitud `horizon`\n",
    "    \"\"\"\n",
    "    # 1. Simular serie\n",
    "    y = simulate_ar1(T, phi, mu, sigma, burn_in, rng)\n",
    "    \n",
    "    # 2. Split train/test\n",
    "    y_train = y[:T - horizon]\n",
    "    y_test = y[T - horizon:]\n",
    "    \n",
    "    # 3. Ajustar ARIMA(1,0,0)\n",
    "    model = ARIMA(y_train, order=(1, 0, 0))\n",
    "    fitted_model = model.fit(disp=False)  # disp=False para no mostrar warnings\n",
    "    \n",
    "    # 4. Pronosticar\n",
    "    y_hat = fitted_model.get_forecast(steps=horizon).predicted_mean.values\n",
    "    \n",
    "    # 5. Calcular errores\n",
    "    errors = y_test - y_hat\n",
    "    \n",
    "    return errors\n",
    "\n",
    "print(\"‚úì Funci√≥n run_one_simulation() definida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Loop Monte Carlo\n",
    "\n",
    "**‚ö†Ô∏è IMPORTANTE**: Esta celda puede tardar varios minutos en ejecutarse (dependiendo de la CPU).\n",
    "\n",
    "Estimaci√≥n: ~2-5 minutos para 500 simulaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Par√°metros del experimento\n",
    "n_sim = 500\n",
    "T = 200\n",
    "horizon = 12\n",
    "phi = 0.7\n",
    "mu = 0.0\n",
    "sigma = 1.0\n",
    "burn_in = 200\n",
    "\n",
    "# Pre-alocar matriz de errores: (n_sim, horizon)\n",
    "error_matrix = np.zeros((n_sim, horizon))\n",
    "\n",
    "# Nuevo RNG para Monte Carlo\n",
    "rng_mc = np.random.default_rng(SEED)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(f\"EJECUTANDO {n_sim} SIMULACIONES MONTE CARLO\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Par√°metros: T={T}, h={horizon}, œÜ={phi}, Œº={mu}, œÉ={sigma}\")\n",
    "print(f\"Seed: {SEED}\")\n",
    "print(\"\\nEsto puede tardar varios minutos...\\n\")\n",
    "\n",
    "for s in range(n_sim):\n",
    "    # Mostrar progreso cada 50 simulaciones\n",
    "    if (s + 1) % 50 == 0:\n",
    "        print(f\"  Progreso: {s+1}/{n_sim} simulaciones completadas ({100*(s+1)/n_sim:.0f}%)\")\n",
    "    \n",
    "    # Ejecutar una simulaci√≥n\n",
    "    errors = run_one_simulation(T, horizon, phi, mu, sigma, burn_in, rng_mc)\n",
    "    \n",
    "    # Almacenar errores\n",
    "    error_matrix[s, :] = errors\n",
    "\n",
    "print(f\"\\n‚úì {n_sim} simulaciones completadas!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Descomposici√≥n Sesgo-Varianza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√°lculo por horizonte\n",
    "bias = error_matrix.mean(axis=0)          # Shape (horizon,)\n",
    "variance = error_matrix.var(axis=0, ddof=1)  # Shape (horizon,)\n",
    "mse = (error_matrix ** 2).mean(axis=0)    # Shape (horizon,)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Crear DataFrame de resultados\n",
    "results = pd.DataFrame({\n",
    "    'horizon': range(1, horizon + 1),\n",
    "    'bias': bias,\n",
    "    'variance': variance,\n",
    "    'mse': mse,\n",
    "    'rmse': rmse\n",
    "})\n",
    "\n",
    "# Agregar fila con promedios\n",
    "avg_row = pd.DataFrame({\n",
    "    'horizon': ['avg_all'],\n",
    "    'bias': [bias.mean()],\n",
    "    'variance': [variance.mean()],\n",
    "    'mse': [mse.mean()],\n",
    "    'rmse': [rmse.mean()]\n",
    "})\n",
    "\n",
    "results = pd.concat([results, avg_row], ignore_index=True)\n",
    "\n",
    "print(\"‚úì M√©tricas calculadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RESULTADOS - ARIMA(1,0,0) en DGP AR(1)\")\n",
    "print(\"=\"*70)\n",
    "print(results.to_string(index=False))\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Mostrar con formato m√°s legible\n",
    "pd.set_option('display.float_format', '{:.6f}'.format)\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 4. Diagn√≥stico de Sesgo\n",
    "\n",
    "Ahora investigamos **por qu√©** el sesgo observado es distinto de cero (si lo es)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Visualizaci√≥n del Sesgo por Horizonte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Gr√°fico 1: Sesgo por horizonte\n",
    "axes[0, 0].plot(range(1, horizon + 1), bias, marker='o', color='red', linewidth=2, markersize=8)\n",
    "axes[0, 0].axhline(0, color='black', linestyle='--', linewidth=1.5)\n",
    "axes[0, 0].set_xlabel('Horizonte (h)', fontsize=11)\n",
    "axes[0, 0].set_ylabel('Sesgo', fontsize=11)\n",
    "axes[0, 0].set_title('Sesgo por Horizonte de Pron√≥stico', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "axes[0, 0].set_xticks(range(1, horizon + 1))\n",
    "\n",
    "# Gr√°fico 2: Varianza por horizonte\n",
    "axes[0, 1].plot(range(1, horizon + 1), variance, marker='s', color='blue', linewidth=2, markersize=8)\n",
    "axes[0, 1].set_xlabel('Horizonte (h)', fontsize=11)\n",
    "axes[0, 1].set_ylabel('Varianza', fontsize=11)\n",
    "axes[0, 1].set_title('Varianza por Horizonte', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "axes[0, 1].set_xticks(range(1, horizon + 1))\n",
    "\n",
    "# Gr√°fico 3: MSE vs Sesgo¬≤ + Varianza\n",
    "bias_squared = bias ** 2\n",
    "mse_decomp = bias_squared + variance\n",
    "axes[1, 0].plot(range(1, horizon + 1), mse, marker='o', label='MSE emp√≠rico', color='darkgreen', linewidth=2, markersize=8)\n",
    "axes[1, 0].plot(range(1, horizon + 1), mse_decomp, marker='x', label='Sesgo¬≤ + Var', color='orange', linewidth=2, markersize=8)\n",
    "axes[1, 0].set_xlabel('Horizonte (h)', fontsize=11)\n",
    "axes[1, 0].set_ylabel('MSE', fontsize=11)\n",
    "axes[1, 0].set_title('Descomposici√≥n MSE', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].legend(fontsize=10)\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "axes[1, 0].set_xticks(range(1, horizon + 1))\n",
    "\n",
    "# Gr√°fico 4: Distribuci√≥n de errores en h=1\n",
    "axes[1, 1].hist(error_matrix[:, 0], bins=30, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "axes[1, 1].axvline(bias[0], color='red', linestyle='--', linewidth=2.5, label=f'Sesgo={bias[0]:.6f}')\n",
    "axes[1, 1].axvline(0, color='black', linestyle='-', linewidth=1.5)\n",
    "axes[1, 1].set_xlabel('Error', fontsize=11)\n",
    "axes[1, 1].set_ylabel('Frecuencia', fontsize=11)\n",
    "axes[1, 1].set_title('Distribuci√≥n de Errores (h=1)', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].legend(fontsize=10)\n",
    "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Observaciones:\")\n",
    "print(f\"  - Sesgo promedio: {bias.mean():.6f}\")\n",
    "print(f\"  - Varianza promedio: {variance.mean():.6f}\")\n",
    "print(f\"  - MSE promedio: {mse.mean():.6f}\")\n",
    "print(f\"  - RMSE promedio: {rmse.mean():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Test de Significancia del Sesgo\n",
    "\n",
    "Realizamos un **t-test de una muestra** para cada horizonte:\n",
    "- $H_0$: El sesgo es cero ($\\mu = 0$)\n",
    "- $H_1$: El sesgo es distinto de cero ($\\mu \\neq 0$)\n",
    "- Nivel de significancia: $\\alpha = 0.05$\n",
    "\n",
    "Si $p < 0.05$, rechazamos $H_0$ ‚Üí el sesgo es **estad√≠sticamente significativo**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TEST DE SIGNIFICANCIA DEL SESGO (t-test de una muestra)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"H0: El sesgo es cero (Œº = 0)\")\n",
    "print(f\"H1: El sesgo es distinto de cero (Œº ‚â† 0)\")\n",
    "print(f\"Nivel de significancia: Œ± = 0.05\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'h':>3s}  {'Sesgo':>12s}  {'t-stat':>10s}  {'p-value':>10s}  {'Sig.':>5s}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "significant_count = 0\n",
    "for h in range(horizon):\n",
    "    errors_h = error_matrix[:, h]\n",
    "    \n",
    "    # t-test de una muestra (H0: media = 0)\n",
    "    t_stat, p_value = stats.ttest_1samp(errors_h, 0)\n",
    "    \n",
    "    significant = \"S√ç\" if p_value < 0.05 else \"NO\"\n",
    "    if p_value < 0.05:\n",
    "        significant_count += 1\n",
    "    \n",
    "    print(f\"{h+1:3d}  {bias[h]:+12.8f}  {t_stat:+10.4f}  {p_value:10.6f}  {significant:>5s}\")\n",
    "\n",
    "print(\"-\"*70)\n",
    "print(f\"\\nResumen:\")\n",
    "print(f\"  - Horizontes con sesgo significativo (Œ±=0.05): {significant_count}/{horizon}\")\n",
    "print(f\"  - Porcentaje de sesgo significativo: {100*significant_count/horizon:.1f}%\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if significant_count == 0:\n",
    "    print(\"\\n‚úì RESULTADO: El sesgo NO es estad√≠sticamente significativo.\")\n",
    "    print(\"  ‚Üí El sesgo observado puede atribuirse a variabilidad muestral.\")\n",
    "elif significant_count < horizon / 2:\n",
    "    print(\"\\n‚ö† RESULTADO: Algunos horizontes muestran sesgo significativo.\")\n",
    "    print(\"  ‚Üí Puede haber sesgo finite-sample en horizontes espec√≠ficos.\")\n",
    "else:\n",
    "    print(\"\\n‚ö† RESULTADO: La mayor√≠a de horizontes muestran sesgo significativo.\")\n",
    "    print(\"  ‚Üí Existe evidencia de sesgo sistem√°tico en los pron√≥sticos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. An√°lisis de Par√°metros Estimados\n",
    "\n",
    "Investigamos si el sesgo proviene de la **estimaci√≥n de par√°metros** (œÜ y Œº).\n",
    "\n",
    "Si $\\hat{\\phi} < \\phi$ sistem√°ticamente, los pron√≥sticos revertir√°n m√°s r√°pido a la media ‚Üí sesgo en pron√≥sticos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar n simulaciones y guardar par√°metros estimados\n",
    "n_check = 100\n",
    "phi_estimates = []\n",
    "mu_estimates = []\n",
    "\n",
    "rng_check = np.random.default_rng(SEED)\n",
    "\n",
    "print(f\"Ejecutando {n_check} simulaciones para analizar par√°metros estimados...\\n\")\n",
    "\n",
    "for s in range(n_check):\n",
    "    y = simulate_ar1(T, phi, mu, sigma, burn_in, rng_check)\n",
    "    y_train = y[:T - horizon]\n",
    "    \n",
    "    model = ARIMA(y_train, order=(1, 0, 0))\n",
    "    fitted = model.fit(disp=False)\n",
    "    \n",
    "    phi_estimates.append(fitted.params['ar.L1'])\n",
    "    mu_estimates.append(fitted.params['const'])\n",
    "\n",
    "phi_estimates = np.array(phi_estimates)\n",
    "mu_estimates = np.array(mu_estimates)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(f\"DISTRIBUCI√ìN DE PAR√ÅMETROS ESTIMADOS (n={n_check})\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nCoeficiente AR (œÜ):\")\n",
    "print(f\"  Valor verdadero:        {phi:.6f}\")\n",
    "print(f\"  Media estimada:         {phi_estimates.mean():.6f}\")\n",
    "print(f\"  Desv. est√°ndar:         {phi_estimates.std():.6f}\")\n",
    "print(f\"  Sesgo de estimaci√≥n:    {phi_estimates.mean() - phi:+.6f}\")\n",
    "print(f\"  Sesgo relativo:         {100*(phi_estimates.mean() - phi)/phi:+.3f}%\")\n",
    "print(f\"\\nConstante (Œº):\")\n",
    "print(f\"  Valor verdadero:        {mu:.6f}\")\n",
    "print(f\"  Media estimada:         {mu_estimates.mean():.6f}\")\n",
    "print(f\"  Desv. est√°ndar:         {mu_estimates.std():.6f}\")\n",
    "print(f\"  Sesgo de estimaci√≥n:    {mu_estimates.mean() - mu:+.6f}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Test de sesgo en par√°metros\n",
    "t_phi, p_phi = stats.ttest_1samp(phi_estimates, phi)\n",
    "t_mu, p_mu = stats.ttest_1samp(mu_estimates, mu)\n",
    "\n",
    "print(f\"\\nTest de sesgo en œÜÃÇ:\")\n",
    "print(f\"  t-statistic: {t_phi:+.4f}\")\n",
    "print(f\"  p-value:     {p_phi:.6f}\")\n",
    "print(f\"  Sesgo significativo (Œ±=0.05): {'S√ç' if p_phi < 0.05 else 'NO'}\")\n",
    "\n",
    "print(f\"\\nTest de sesgo en ŒºÃÇ:\")\n",
    "print(f\"  t-statistic: {t_mu:+.4f}\")\n",
    "print(f\"  p-value:     {p_mu:.6f}\")\n",
    "print(f\"  Sesgo significativo (Œ±=0.05): {'S√ç' if p_mu < 0.05 else 'NO'}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizaci√≥n de Par√°metros Estimados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Distribuci√≥n de œÜÃÇ\n",
    "axes[0].hist(phi_estimates, bins=25, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "axes[0].axvline(phi, color='red', linestyle='--', linewidth=2.5, label=f'Verdadero œÜ={phi}')\n",
    "axes[0].axvline(phi_estimates.mean(), color='orange', linestyle='-', linewidth=2.5, label=f'Media œÜÃÇ={phi_estimates.mean():.4f}')\n",
    "axes[0].set_xlabel('œÜÃÇ estimado', fontsize=11)\n",
    "axes[0].set_ylabel('Frecuencia', fontsize=11)\n",
    "axes[0].set_title('Distribuci√≥n de œÜÃÇ (Coef. AR)', fontsize=12, fontweight='bold')\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Distribuci√≥n de ŒºÃÇ\n",
    "axes[1].hist(mu_estimates, bins=25, edgecolor='black', alpha=0.7, color='coral')\n",
    "axes[1].axvline(mu, color='red', linestyle='--', linewidth=2.5, label=f'Verdadero Œº={mu}')\n",
    "axes[1].axvline(mu_estimates.mean(), color='orange', linestyle='-', linewidth=2.5, label=f'Media ŒºÃÇ={mu_estimates.mean():.4f}')\n",
    "axes[1].set_xlabel('ŒºÃÇ estimado', fontsize=11)\n",
    "axes[1].set_ylabel('Frecuencia', fontsize=11)\n",
    "axes[1].set_title('Distribuci√≥n de ŒºÃÇ (Constante)', fontsize=12, fontweight='bold')\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Interpretaci√≥n:\")\n",
    "if abs(phi_estimates.mean() - phi) > 0.01:\n",
    "    print(f\"  - Se observa sesgo en la estimaci√≥n de œÜ: {phi_estimates.mean() - phi:+.6f}\")\n",
    "    print(\"  - Este sesgo finite-sample puede propagarse a los pron√≥sticos\")\n",
    "else:\n",
    "    print(\"  - La estimaci√≥n de œÜ es aproximadamente insesgada\")\n",
    "    print(\"  - El sesgo en pron√≥sticos (si existe) no proviene de œÜÃÇ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 5. Experimentos Adicionales\n",
    "\n",
    "Variamos par√°metros para entender **cu√°ndo aparece/desaparece el sesgo**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Efecto de T (Longitud de Serie)\n",
    "\n",
    "¬øEl sesgo desaparece con m√°s datos de entrenamiento?\n",
    "\n",
    "Probamos con $T \\in \\{100, 200, 500, 1000\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_values = [100, 200, 500, 1000]\n",
    "bias_by_T = {}\n",
    "n_sim_reduced = 100  # Reducir a 100 sims para velocidad\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"EXPERIMENTO: Efecto de la Longitud de Serie (T)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Probando T = {T_values}\")\n",
    "print(f\"Simulaciones por T: {n_sim_reduced}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "for T_test in T_values:\n",
    "    print(f\"Ejecutando MC con T={T_test}...\")\n",
    "    \n",
    "    error_matrix_T = np.zeros((n_sim_reduced, horizon))\n",
    "    rng_T = np.random.default_rng(SEED)\n",
    "    \n",
    "    for s in range(n_sim_reduced):\n",
    "        errors = run_one_simulation(T_test, horizon, phi, mu, sigma, burn_in, rng_T)\n",
    "        error_matrix_T[s, :] = errors\n",
    "    \n",
    "    bias_T = error_matrix_T.mean(axis=0)\n",
    "    bias_by_T[T_test] = bias_T\n",
    "    \n",
    "    print(f\"  Sesgo promedio: {bias_T.mean():+.6f}\\n\")\n",
    "\n",
    "print(\"‚úì Experimento completado\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar resultados\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "for T_test in T_values:\n",
    "    plt.plot(range(1, horizon + 1), bias_by_T[T_test], marker='o', linewidth=2, markersize=6, label=f'T={T_test}')\n",
    "\n",
    "plt.axhline(0, color='black', linestyle='--', linewidth=1.5)\n",
    "plt.xlabel('Horizonte (h)', fontsize=12)\n",
    "plt.ylabel('Sesgo', fontsize=12)\n",
    "plt.title('Efecto de la Longitud de Serie (T) en el Sesgo', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(range(1, horizon + 1))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Observaciones:\")\n",
    "for T_test in T_values:\n",
    "    print(f\"  T={T_test:4d}: Sesgo promedio = {bias_by_T[T_test].mean():+.6f}\")\n",
    "\n",
    "print(\"\\nüí° Interpretaci√≥n esperada:\")\n",
    "print(\"  - Si el sesgo disminuye con T ‚Üí sesgo finite-sample\")\n",
    "print(\"  - Si el sesgo NO disminuye ‚Üí problema de especificaci√≥n del modelo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Efecto de œÜ (Persistencia)\n",
    "\n",
    "¬øEl sesgo depende de la persistencia del proceso?\n",
    "\n",
    "Probamos con $\\phi \\in \\{0.3, 0.5, 0.7, 0.9\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_values = [0.3, 0.5, 0.7, 0.9]\n",
    "bias_by_phi = {}\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"EXPERIMENTO: Efecto de la Persistencia (œÜ)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Probando œÜ = {phi_values}\")\n",
    "print(f\"Simulaciones por œÜ: {n_sim_reduced}\")\n",
    "print(f\"T fijo: {T}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "for phi_test in phi_values:\n",
    "    print(f\"Ejecutando MC con œÜ={phi_test}...\")\n",
    "    \n",
    "    error_matrix_phi = np.zeros((n_sim_reduced, horizon))\n",
    "    rng_phi = np.random.default_rng(SEED)\n",
    "    \n",
    "    for s in range(n_sim_reduced):\n",
    "        errors = run_one_simulation(T, horizon, phi_test, mu, sigma, burn_in, rng_phi)\n",
    "        error_matrix_phi[s, :] = errors\n",
    "    \n",
    "    bias_phi = error_matrix_phi.mean(axis=0)\n",
    "    bias_by_phi[phi_test] = bias_phi\n",
    "    \n",
    "    print(f\"  Sesgo promedio: {bias_phi.mean():+.6f}\\n\")\n",
    "\n",
    "print(\"‚úì Experimento completado\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar resultados\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "for phi_test in phi_values:\n",
    "    plt.plot(range(1, horizon + 1), bias_by_phi[phi_test], marker='o', linewidth=2, markersize=6, label=f'œÜ={phi_test}')\n",
    "\n",
    "plt.axhline(0, color='black', linestyle='--', linewidth=1.5)\n",
    "plt.xlabel('Horizonte (h)', fontsize=12)\n",
    "plt.ylabel('Sesgo', fontsize=12)\n",
    "plt.title('Efecto de la Persistencia (œÜ) en el Sesgo', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(range(1, horizon + 1))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Observaciones:\")\n",
    "for phi_test in phi_values:\n",
    "    print(f\"  œÜ={phi_test}: Sesgo promedio = {bias_by_phi[phi_test].mean():+.6f}\")\n",
    "\n",
    "print(\"\\nüí° Interpretaci√≥n esperada:\")\n",
    "print(\"  - Mayor œÜ ‚Üí mayor persistencia ‚Üí pron√≥sticos m√°s lentos a revertir\")\n",
    "print(\"  - Si el sesgo crece con œÜ ‚Üí sesgo propagado por estimaci√≥n de par√°metros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 6. Conclusiones y Validaci√≥n\n",
    "\n",
    "## Resumen de Hallazgos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"RESUMEN DE HALLAZGOS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n1. SESGO OBSERVADO (500 simulaciones, T=200, œÜ=0.7)\")\n",
    "print(\"-\"*70)\n",
    "print(f\"   Sesgo promedio:      {bias.mean():+.8f}\")\n",
    "print(f\"   Sesgo m√°ximo (h):    {bias.max():+.8f} (h={bias.argmax()+1})\")\n",
    "print(f\"   Sesgo m√≠nimo (h):    {bias.min():+.8f} (h={bias.argmin()+1})\")\n",
    "\n",
    "# Contar cu√°ntos horizontes tienen sesgo significativo\n",
    "sig_count = sum([1 for h in range(horizon) if stats.ttest_1samp(error_matrix[:, h], 0)[1] < 0.05])\n",
    "print(f\"\\n   Horizontes con sesgo significativo (Œ±=0.05): {sig_count}/{horizon}\")\n",
    "\n",
    "print(\"\\n2. PATR√ìN DEL SESGO\")\n",
    "print(\"-\"*70)\n",
    "# Detectar si crece, decrece o es constante\n",
    "if bias[-1] > bias[0] * 1.2:\n",
    "    print(\"   Patr√≥n: CRECIENTE con el horizonte\")\n",
    "elif bias[-1] < bias[0] * 0.8:\n",
    "    print(\"   Patr√≥n: DECRECIENTE con el horizonte\")\n",
    "else:\n",
    "    print(\"   Patr√≥n: APROXIMADAMENTE CONSTANTE\")\n",
    "\n",
    "print(\"\\n3. M√âTRICAS ADICIONALES\")\n",
    "print(\"-\"*70)\n",
    "print(f\"   Varianza promedio:   {variance.mean():.6f}\")\n",
    "print(f\"   MSE promedio:        {mse.mean():.6f}\")\n",
    "print(f\"   RMSE promedio:       {rmse.mean():.6f}\")\n",
    "\n",
    "print(\"\\n4. AN√ÅLISIS DE PAR√ÅMETROS ESTIMADOS\")\n",
    "print(\"-\"*70)\n",
    "print(f\"   Sesgo en œÜÃÇ:          {phi_estimates.mean() - phi:+.6f} ({100*(phi_estimates.mean() - phi)/phi:+.2f}%)\")\n",
    "print(f\"   Sesgo significativo: {'S√ç' if stats.ttest_1samp(phi_estimates, phi)[1] < 0.05 else 'NO'}\")\n",
    "\n",
    "print(\"\\n5. EFECTO DE T (LONGITUD DE SERIE)\")\n",
    "print(\"-\"*70)\n",
    "for T_test in T_values:\n",
    "    print(f\"   T={T_test:4d}: Sesgo promedio = {bias_by_T[T_test].mean():+.6f}\")\n",
    "\n",
    "print(\"\\n6. EFECTO DE œÜ (PERSISTENCIA)\")\n",
    "print(\"-\"*70)\n",
    "for phi_test in phi_values:\n",
    "    print(f\"   œÜ={phi_test}: Sesgo promedio = {bias_by_phi[phi_test].mean():+.6f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CONCLUSI√ìN GENERAL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if sig_count == 0:\n",
    "    print(\"\"\"\n",
    "‚úì El sesgo observado NO es estad√≠sticamente significativo.\n",
    "  \n",
    "  ‚Üí ARIMA(1,0,0) es aproximadamente insesgado para DGP AR(1).\n",
    "  ‚Üí El sesgo observado puede atribuirse a variabilidad muestral.\n",
    "  ‚Üí Con n_sim = 500, este nivel de sesgo es esperado.\n",
    "  ‚Üí VALIDACI√ìN EXITOSA: El modelo se comporta como se espera te√≥ricamente.\n",
    "\"\"\")\n",
    "elif sig_count < horizon / 3:\n",
    "    print(\"\"\"\n",
    "‚ö† Algunos horizontes muestran sesgo significativo.\n",
    "  \n",
    "  ‚Üí Puede existir sesgo finite-sample en la estimaci√≥n de par√°metros.\n",
    "  ‚Üí El sesgo es peque√±o en magnitud absoluta.\n",
    "  ‚Üí Considerar aumentar T (longitud de serie de entrenamiento).\n",
    "  ‚Üí VALIDACI√ìN PARCIAL: Comportamiento mayormente correcto con peque√±as desviaciones.\n",
    "\"\"\")\n",
    "else:\n",
    "    print(\"\"\"\n",
    "‚ö† La mayor√≠a de horizontes muestran sesgo estad√≠sticamente significativo.\n",
    "  \n",
    "  ‚Üí Existe evidencia de sesgo sistem√°tico en los pron√≥sticos.\n",
    "  ‚Üí Posibles causas:\n",
    "    1. Sesgo finite-sample en estimaci√≥n de œÜ (verificar an√°lisis de par√°metros)\n",
    "    2. Muestra de entrenamiento insuficiente (T_train = 188)\n",
    "    3. Horizonte de pron√≥stico largo (h=12 es significativo para AR(1))\n",
    "  \n",
    "  ‚Üí Acciones recomendadas:\n",
    "    1. Aumentar T (probar con T=500 o T=1000)\n",
    "    2. Reducir horizonte (probar con h=6)\n",
    "    3. Aplicar correcci√≥n de sesgo finite-sample\n",
    "    4. Comparar con otros paquetes (pmdarima, R forecast)\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2. Comparaci√≥n con Experimento Original\n",
    "\n",
    "**Nota**: Si ya corriste el experimento con `scripts/run_experiment.py`, copia los resultados aqu√≠ para compararlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPCIONAL: Completar con resultados del experimento original\n",
    "# Si no tienes los resultados, omite esta celda\n",
    "\n",
    "# Ejemplo (reemplaza con tus valores reales):\n",
    "# results_original = pd.DataFrame({\n",
    "#     'horizon': range(1, 13),\n",
    "#     'bias': [0.0123, 0.0234, ...],  # Valores del experimento original\n",
    "#     'variance': [...],\n",
    "#     'mse': [...],\n",
    "#     'rmse': [...]\n",
    "# })\n",
    "\n",
    "# results_notebook = results.iloc[:-1].copy()  # Excluir fila avg_all\n",
    "\n",
    "# comparison = pd.DataFrame({\n",
    "#     'horizon': results_notebook['horizon'],\n",
    "#     'bias_original': results_original['bias'],\n",
    "#     'bias_notebook': results_notebook['bias'],\n",
    "#     'diff_bias': results_notebook['bias'] - results_original['bias']\n",
    "# })\n",
    "\n",
    "# print(\"\\n\" + \"=\"*70)\n",
    "# print(\"COMPARACI√ìN: Experimento Original vs Notebook\")\n",
    "# print(\"=\"*70)\n",
    "# print(comparison.to_string(index=False))\n",
    "# print(\"=\"*70)\n",
    "\n",
    "# max_diff = comparison['diff_bias'].abs().max()\n",
    "# print(f\"\\nDiferencia m√°xima en sesgo: {max_diff:.6f}\")\n",
    "# if max_diff < 1e-10:\n",
    "#     print(\"‚úì Resultados ID√âNTICOS (diferencia < 1e-10)\")\n",
    "# elif max_diff < 1e-6:\n",
    "#     print(\"‚úì Resultados PR√ÅCTICAMENTE ID√âNTICOS (diferencia < 1e-6)\")\n",
    "# else:\n",
    "#     print(\"‚ö† RESULTADOS DIFIEREN - Investigar diferencias de implementaci√≥n\")\n",
    "\n",
    "print(\"\\n‚ö† Esta celda est√° comentada. Descomenta y completa con tus resultados originales si los tienes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Fin del Notebook\n",
    "\n",
    "Este notebook implement√≥:\n",
    "\n",
    "1. ‚úÖ Simulaci√≥n paso a paso de AR(1)\n",
    "2. ‚úÖ Ajuste y pron√≥stico con ARIMA(1,0,0)\n",
    "3. ‚úÖ Monte Carlo con 500 simulaciones\n",
    "4. ‚úÖ Descomposici√≥n sesgo-varianza\n",
    "5. ‚úÖ Test de significancia del sesgo\n",
    "6. ‚úÖ An√°lisis de par√°metros estimados\n",
    "7. ‚úÖ Experimentos de sensibilidad (T, œÜ)\n",
    "\n",
    "**Pr√≥ximos pasos**:\n",
    "- Comparar con resultados de `scripts/run_experiment.py`\n",
    "- Si el sesgo es significativo, investigar causas (finite-sample bias)\n",
    "- Documentar hallazgos en la tesis\n",
    "\n",
    "---\n",
    "\n",
    "**Autor**: David Guzzi  \n",
    "**Fecha**: 2025-12-01  \n",
    "**Tesis**: Maestr√≠a en Econometr√≠a - MECTESIS  \n",
    "**Seed**: 12345 (reproducible)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
